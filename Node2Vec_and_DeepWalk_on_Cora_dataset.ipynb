{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMvZsVXbntthcEcEQAAFfm6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ln5vUqW0SmnD","executionInfo":{"status":"ok","timestamp":1684147296747,"user_tz":-420,"elapsed":4660443,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"b4961ebd-d24c-4fc7-b0f1-fa6776219279"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Install required packages.\n","!pip install -q torch-cluster \n","!pip install -q torch-scatter \n","!pip install -q torch-sparse \n","!pip install -q torch-geometric"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMcqxJDeh97L","executionInfo":{"status":"ok","timestamp":1684147337191,"user_tz":-420,"elapsed":4121,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"c4d9c9ed-d045-4d9e-b4b1-a2ce08ca5c9c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from torch_geometric.nn import Node2Vec\n","import os.path as osp\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from torch_geometric.datasets import Planetoid\n","from tqdm.notebook import tqdm\n","import os\n","\n","PRJ_DIR = os.path.join('/','content','drive','MyDrive','Colab Notebooks','eliorc_node2vec')\n","DATA_DIR = os.path.join(PRJ_DIR,'Facebook-Social-Network-Analysis-master')\n","\n","dataset = 'Cora'\n","path = osp.join('.', 'data', dataset)\n","dataset = Planetoid(path, dataset)\n","data = dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_CL8yDGTIEq","executionInfo":{"status":"ok","timestamp":1684147345504,"user_tz":-420,"elapsed":8315,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"3eb2af97-0205-4657-98a3-2a88eb2b07b8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","edge_tensor = torch.permute(data.edge_index, (1, 0))\n","cora_df = pd.DataFrame(edge_tensor, columns = ['Source','Destination'])\n","print(cora_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVov7Ey4eBpi","executionInfo":{"status":"ok","timestamp":1684147345505,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"b071f378-1cbd-4233-c458-6fab6286ff2d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["   Source  Destination\n","0       0          633\n","1       0         1862\n","2       0         2582\n","3       1            2\n","4       1          652\n"]}]},{"cell_type":"code","source":["#@title Creating graph\n","\n","import networkx as nx\n","\n","#creating a list of node pair tuples from the 'cora_df' dataframe\n","existing_edges = [(cora_df.iloc[i,0],cora_df.iloc[i,1]) for i in range(cora_df.shape[0])]\n","\n","cora_G = nx.from_pandas_edgelist(cora_df, \"Source\", \"Destination\", create_using=nx.DiGraph())\n","\n","#cora_G.add_edges_from(existing_edges)\n","print(\"------Before Dropping nodes with low degree (<3)-----\")\n","print('Number of nodes', len(cora_G.nodes))\n","print('Number of edges', len(cora_G.edges))\n","print('Average degree', sum(dict(cora_G.degree).values()) / len(cora_G.nodes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684147346310,"user_tz":-420,"elapsed":807,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"096a7b71-811e-4ea0-eb80-a88ebd76e214","id":"cDqxOkDKKkuh"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["------Before Dropping nodes with low degree (<3)-----\n","Number of nodes 2708\n","Number of edges 10556\n","Average degree 7.796159527326441\n"]}]},{"cell_type":"code","source":["print(cora_G.has_edge(2, 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5nlR_MQk_cM","executionInfo":{"status":"ok","timestamp":1684147346311,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"bed3edde-b657-4edb-85aa-5c91749d4e44"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684147346311,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"},"user_tz":-420},"id":"Lt3GscDt0qYR","outputId":"4e1006f2-5eac-4b2a-f945-c1efe3fd7703"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2708, 2708)\n","\n","[[0. 1. 1. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}],"source":["#@title Creating Adjacency Matrix\n","\n","nodelist = list(cora_G.nodes())\n","adj_cora = nx.to_numpy_array(cora_G, nodelist = nodelist)\n","print(str(adj_cora.shape)+'\\n')\n","print(adj_cora)"]},{"cell_type":"code","source":["import random\n","\n","non_existing_edges_20000 = []\n","while(len(non_existing_edges_20000) < 20000):\n","    source_idx = random.randint(0, adj_cora.shape[0]-1)\n","    destination_idx = random.randint(0, adj_cora.shape[1]-1)\n","    if source_idx == destination_idx or adj_cora[source_idx, destination_idx] == 1:\n","        continue\n","\n","    if nx.has_path(cora_G, nodelist[source_idx], nodelist[destination_idx]):\n","        non_existing_edges_20000.extend([(nodelist[source_idx],nodelist[destination_idx])])\n","    \n","\n","non_existing_edge_df = pd.DataFrame(data = non_existing_edges_20000, columns =['Source', 'Destination'])\n","non_existing_edge_df['Connection'] = 0\n","print(non_existing_edge_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1vNQLsMhocB","executionInfo":{"status":"ok","timestamp":1684147347596,"user_tz":-420,"elapsed":1287,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"e1bd9463-cf13-43b1-d4e6-371ddfd148f7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["   Source  Destination  Connection\n","0    2099          942           0\n","1    2374         2588           0\n","2    2653         1156           0\n","3    1889         1211           0\n","4    2284         1062           0\n"]}]},{"cell_type":"code","source":["cora_df[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"HLsfJME2kgMy","executionInfo":{"status":"ok","timestamp":1684147347596,"user_tz":-420,"elapsed":11,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"f1a40a6a-ed45-4f81-d26c-da689826976c"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Source  Destination\n","0       0          633\n","1       0         1862\n","2       0         2582\n","3       1            2\n","4       1          652\n","5       1          654\n","6       2            1\n","7       2          332\n","8       2         1454\n","9       2         1666"],"text/html":["\n","  <div id=\"df-21ae75a3-19bb-436a-909c-b6b5b3226a0d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Source</th>\n","      <th>Destination</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>633</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1862</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2582</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>652</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>654</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2</td>\n","      <td>332</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>1454</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2</td>\n","      <td>1666</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21ae75a3-19bb-436a-909c-b6b5b3226a0d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-21ae75a3-19bb-436a-909c-b6b5b3226a0d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-21ae75a3-19bb-436a-909c-b6b5b3226a0d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684147347597,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"},"user_tz":-420},"id":"CBjb8lu--XMB","outputId":"6893633f-97d8-422a-8681-f24740aed471"},"outputs":[{"output_type":"stream","name":"stdout","text":["      Source  Destination  Connection\n","9496    2309          994           1\n","2943     734          408           1\n","783      175         2135           1\n","391       91         2123           1\n","1168     290         1765           1\n"]}],"source":["remove_edge_df = cora_df.sample(n=len(cora_df.index)//2, random_state=1)\n","remove_edge_df['Connection'] = 1\n","print(remove_edge_df.head())"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684147347597,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"},"user_tz":-420},"id":"aceYdxVfbTAM","outputId":"042a6d69-aa56-4002-e1fb-1cd33d5ceb24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of nodes 2559\n","Number of edges 5278\n","Average degree 4.12504884720594\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-79d86168b2a7>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  non_existing_edge_df = non_existing_edge_df.append(remove_edge_df[['Source', 'Destination', 'Connection']],\n"]}],"source":["#@title Creating Subgraph\n","non_existing_edge_df = non_existing_edge_df.append(remove_edge_df[['Source', 'Destination', 'Connection']],\n","                ignore_index=True)\n","\n","edges_cora_G_past = cora_df.drop(index=remove_edge_df.index.values)\n","\n","cora_G_new = nx.from_pandas_edgelist(edges_cora_G_past, \"Source\", \"Destination\",\n","                               create_using=nx.DiGraph())\n","\n","print('Number of nodes', len(cora_G_new.nodes))\n","print('Number of edges', len(cora_G_new.edges))\n","print('Average degree', sum(dict(cora_G_new.degree).values()) / len(cora_G_new.nodes))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WxloU9pK-vLc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684151417671,"user_tz":-420,"elapsed":3590679,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"786e360f-e643-47f7-c9c6-ccc1dcc05787"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------Training with p=0.25 and q=0.25--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0771\n","Epoch: 30, Loss: 0.8102\n","Epoch: 45, Loss: 0.7756\n","Epoch: 60, Loss: 0.7654\n","Epoch: 75, Loss: 0.7607\n","Epoch: 90, Loss: 0.7599\n","Epoch: 105, Loss: 0.7585\n","Epoch: 120, Loss: 0.7574\n","Epoch: 135, Loss: 0.7576\n","-------Training with p=0.25 and q=0.5--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1024\n","Epoch: 30, Loss: 0.8145\n","Epoch: 45, Loss: 0.7751\n","Epoch: 60, Loss: 0.7633\n","Epoch: 75, Loss: 0.7575\n","Epoch: 90, Loss: 0.7558\n","Epoch: 105, Loss: 0.7543\n","Epoch: 120, Loss: 0.7535\n","Epoch: 135, Loss: 0.7523\n","-------Training with p=0.25 and q=1--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1173\n","Epoch: 30, Loss: 0.8138\n","Epoch: 45, Loss: 0.7722\n","Epoch: 60, Loss: 0.7591\n","Epoch: 75, Loss: 0.7527\n","Epoch: 90, Loss: 0.7496\n","Epoch: 105, Loss: 0.7484\n","Epoch: 120, Loss: 0.7483\n","Epoch: 135, Loss: 0.7469\n","-------Training with p=0.25 and q=2--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1467\n","Epoch: 30, Loss: 0.8193\n","Epoch: 45, Loss: 0.7717\n","Epoch: 60, Loss: 0.7561\n","Epoch: 75, Loss: 0.7488\n","Epoch: 90, Loss: 0.7456\n","Epoch: 105, Loss: 0.7429\n","Epoch: 120, Loss: 0.7425\n","Epoch: 135, Loss: 0.7416\n","-------Training with p=0.25 and q=4--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1617\n","Epoch: 30, Loss: 0.8254\n","Epoch: 45, Loss: 0.7732\n","Epoch: 60, Loss: 0.7547\n","Epoch: 75, Loss: 0.7462\n","Epoch: 90, Loss: 0.7412\n","Epoch: 105, Loss: 0.7393\n","Epoch: 120, Loss: 0.7374\n","Epoch: 135, Loss: 0.7361\n","-------Training with p=0.5 and q=0.25--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0802\n","Epoch: 30, Loss: 0.8104\n","Epoch: 45, Loss: 0.7753\n","Epoch: 60, Loss: 0.7642\n","Epoch: 75, Loss: 0.7621\n","Epoch: 90, Loss: 0.7592\n","Epoch: 105, Loss: 0.7584\n","Epoch: 120, Loss: 0.7583\n","Epoch: 135, Loss: 0.7570\n","-------Training with p=0.5 and q=0.5--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0800\n","Epoch: 30, Loss: 0.8115\n","Epoch: 45, Loss: 0.7776\n","Epoch: 60, Loss: 0.7671\n","Epoch: 75, Loss: 0.7618\n","Epoch: 90, Loss: 0.7609\n","Epoch: 105, Loss: 0.7592\n","Epoch: 120, Loss: 0.7581\n","Epoch: 135, Loss: 0.7577\n","-------Training with p=0.5 and q=1--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0974\n","Epoch: 30, Loss: 0.8104\n","Epoch: 45, Loss: 0.7722\n","Epoch: 60, Loss: 0.7619\n","Epoch: 75, Loss: 0.7567\n","Epoch: 90, Loss: 0.7542\n","Epoch: 105, Loss: 0.7530\n","Epoch: 120, Loss: 0.7521\n","Epoch: 135, Loss: 0.7526\n","-------Training with p=0.5 and q=2--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1146\n","Epoch: 30, Loss: 0.8110\n","Epoch: 45, Loss: 0.7698\n","Epoch: 60, Loss: 0.7571\n","Epoch: 75, Loss: 0.7513\n","Epoch: 90, Loss: 0.7491\n","Epoch: 105, Loss: 0.7479\n","Epoch: 120, Loss: 0.7471\n","Epoch: 135, Loss: 0.7470\n","-------Training with p=0.5 and q=4--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1498\n","Epoch: 30, Loss: 0.8201\n","Epoch: 45, Loss: 0.7729\n","Epoch: 60, Loss: 0.7555\n","Epoch: 75, Loss: 0.7480\n","Epoch: 90, Loss: 0.7444\n","Epoch: 105, Loss: 0.7431\n","Epoch: 120, Loss: 0.7421\n","Epoch: 135, Loss: 0.7412\n","-------Training with p=1 and q=0.25--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0829\n","Epoch: 30, Loss: 0.8120\n","Epoch: 45, Loss: 0.7771\n","Epoch: 60, Loss: 0.7665\n","Epoch: 75, Loss: 0.7625\n","Epoch: 90, Loss: 0.7605\n","Epoch: 105, Loss: 0.7595\n","Epoch: 120, Loss: 0.7583\n","Epoch: 135, Loss: 0.7590\n","-------Training with p=1 and q=0.5--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0685\n","Epoch: 30, Loss: 0.8087\n","Epoch: 45, Loss: 0.7754\n","Epoch: 60, Loss: 0.7662\n","Epoch: 75, Loss: 0.7606\n","Epoch: 90, Loss: 0.7597\n","Epoch: 105, Loss: 0.7587\n","Epoch: 120, Loss: 0.7584\n","Epoch: 135, Loss: 0.7585\n","-------Training with p=1 and q=1--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0805\n","Epoch: 30, Loss: 0.8108\n","Epoch: 45, Loss: 0.7763\n","Epoch: 60, Loss: 0.7659\n","Epoch: 75, Loss: 0.7614\n","Epoch: 90, Loss: 0.7599\n","Epoch: 105, Loss: 0.7590\n","Epoch: 120, Loss: 0.7580\n","Epoch: 135, Loss: 0.7586\n","-------Training with p=1 and q=2--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0971\n","Epoch: 30, Loss: 0.8105\n","Epoch: 45, Loss: 0.7729\n","Epoch: 60, Loss: 0.7606\n","Epoch: 75, Loss: 0.7563\n","Epoch: 90, Loss: 0.7541\n","Epoch: 105, Loss: 0.7535\n","Epoch: 120, Loss: 0.7518\n","Epoch: 135, Loss: 0.7512\n","-------Training with p=1 and q=4--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1246\n","Epoch: 30, Loss: 0.8159\n","Epoch: 45, Loss: 0.7727\n","Epoch: 60, Loss: 0.7588\n","Epoch: 75, Loss: 0.7523\n","Epoch: 90, Loss: 0.7495\n","Epoch: 105, Loss: 0.7473\n","Epoch: 120, Loss: 0.7470\n","Epoch: 135, Loss: 0.7468\n","-------Training with p=2 and q=0.25--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0766\n","Epoch: 30, Loss: 0.8090\n","Epoch: 45, Loss: 0.7756\n","Epoch: 60, Loss: 0.7658\n","Epoch: 75, Loss: 0.7606\n","Epoch: 90, Loss: 0.7590\n","Epoch: 105, Loss: 0.7588\n","Epoch: 120, Loss: 0.7580\n","Epoch: 135, Loss: 0.7575\n","-------Training with p=2 and q=0.5--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0805\n","Epoch: 30, Loss: 0.8127\n","Epoch: 45, Loss: 0.7770\n","Epoch: 60, Loss: 0.7668\n","Epoch: 75, Loss: 0.7620\n","Epoch: 90, Loss: 0.7598\n","Epoch: 105, Loss: 0.7585\n","Epoch: 120, Loss: 0.7585\n","Epoch: 135, Loss: 0.7573\n","-------Training with p=2 and q=1--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0763\n","Epoch: 30, Loss: 0.8087\n","Epoch: 45, Loss: 0.7754\n","Epoch: 60, Loss: 0.7655\n","Epoch: 75, Loss: 0.7609\n","Epoch: 90, Loss: 0.7589\n","Epoch: 105, Loss: 0.7594\n","Epoch: 120, Loss: 0.7582\n","Epoch: 135, Loss: 0.7580\n","-------Training with p=2 and q=2--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0745\n","Epoch: 30, Loss: 0.8079\n","Epoch: 45, Loss: 0.7742\n","Epoch: 60, Loss: 0.7643\n","Epoch: 75, Loss: 0.7599\n","Epoch: 90, Loss: 0.7581\n","Epoch: 105, Loss: 0.7578\n","Epoch: 120, Loss: 0.7575\n","Epoch: 135, Loss: 0.7570\n","-------Training with p=2 and q=4--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.1004\n","Epoch: 30, Loss: 0.8109\n","Epoch: 45, Loss: 0.7729\n","Epoch: 60, Loss: 0.7611\n","Epoch: 75, Loss: 0.7557\n","Epoch: 90, Loss: 0.7536\n","Epoch: 105, Loss: 0.7518\n","Epoch: 120, Loss: 0.7515\n","Epoch: 135, Loss: 0.7509\n","-------Training with p=4 and q=0.25--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0936\n","Epoch: 30, Loss: 0.8132\n","Epoch: 45, Loss: 0.7760\n","Epoch: 60, Loss: 0.7668\n","Epoch: 75, Loss: 0.7620\n","Epoch: 90, Loss: 0.7595\n","Epoch: 105, Loss: 0.7580\n","Epoch: 120, Loss: 0.7575\n","Epoch: 135, Loss: 0.7581\n","-------Training with p=4 and q=0.5--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0837\n","Epoch: 30, Loss: 0.8116\n","Epoch: 45, Loss: 0.7766\n","Epoch: 60, Loss: 0.7661\n","Epoch: 75, Loss: 0.7616\n","Epoch: 90, Loss: 0.7595\n","Epoch: 105, Loss: 0.7584\n","Epoch: 120, Loss: 0.7579\n","Epoch: 135, Loss: 0.7587\n","-------Training with p=4 and q=1--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0812\n","Epoch: 30, Loss: 0.8118\n","Epoch: 45, Loss: 0.7766\n","Epoch: 60, Loss: 0.7665\n","Epoch: 75, Loss: 0.7620\n","Epoch: 90, Loss: 0.7602\n","Epoch: 105, Loss: 0.7591\n","Epoch: 120, Loss: 0.7580\n","Epoch: 135, Loss: 0.7583\n","-------Training with p=4 and q=2--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0814\n","Epoch: 30, Loss: 0.8099\n","Epoch: 45, Loss: 0.7756\n","Epoch: 60, Loss: 0.7650\n","Epoch: 75, Loss: 0.7609\n","Epoch: 90, Loss: 0.7593\n","Epoch: 105, Loss: 0.7582\n","Epoch: 120, Loss: 0.7576\n","Epoch: 135, Loss: 0.7568\n","-------Training with p=4 and q=4--------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15, Loss: 1.0871\n","Epoch: 30, Loss: 0.8105\n","Epoch: 45, Loss: 0.7743\n","Epoch: 60, Loss: 0.7632\n","Epoch: 75, Loss: 0.7585\n","Epoch: 90, Loss: 0.7564\n","Epoch: 105, Loss: 0.7564\n","Epoch: 120, Loss: 0.7553\n","Epoch: 135, Loss: 0.7547\n"]}],"source":["from torch_geometric.nn import Node2Vec\n","import os.path as osp\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from torch_geometric.datasets import Planetoid\n","from tqdm.notebook import tqdm\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.metrics import f1_score, auc, roc_curve, roc_auc_score,confusion_matrix\n","from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n","import numpy as np\n","\n","def train(model, loader, optimizer):\n","    model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in loader:\n","        optimizer.zero_grad()\n","        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","edges_tensor = torch.from_numpy(edges_cora_G_past.to_numpy())\n","edges_tensor = torch.permute(edges_tensor, (1, 0))\n","\n","set_of_pq = [0.25, 0.50, 1, 2, 4]\n","\n","model_pool = {}\n","\n","for p_value in set_of_pq:\n","    for q_value in set_of_pq:\n","        node2vec = Node2Vec(edge_index = edges_tensor,\n","                    embedding_dim = 128,\n","                    walk_length = 16,\n","                    context_size = 10,\n","                    walks_per_node = 20,\n","                    p=p_value, q=q_value).to(device)\n","\n","        loader = node2vec.loader(batch_size=128, shuffle=True, num_workers=4)\n","        optimizer = torch.optim.Adam(list(node2vec.parameters()), lr=0.01)\n","\n","        print(f\"-------Training with p={p_value} and q={q_value}--------\")\n","        for epoch in range(1, 150):\n","            loss = train(node2vec, loader, optimizer)\n","            if epoch % 15 == 0:\n","                print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n","\n","        embedding_nodes = node2vec(torch.arange(node2vec.embedding.weight.size()[0], device=device))\n","\n","        edge_features = [\n","            (embedding_nodes[i].detach().cpu().numpy() + embedding_nodes[j].detach().cpu().numpy()) \n","            for i,j in zip(non_existing_edge_df['Source'], non_existing_edge_df['Destination'])\n","        ]\n","\n","        X = np.array(edge_features)  \n","        y = non_existing_edge_df['Connection']\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = random.randint(0, 999999))\n","\n","        #classifier\n","        random_forest_clf = RandomForestClassifier(n_estimators=100, max_depth=15)\n","        \n","        # alternative metric to optimize over grid parameters: AUC\n","        random_forest_clf.fit(X_train, y_train)\n","        \n","        model_pool[f\"model_pq:{p_value}_{q_value}\"] = random_forest_clf\n","        model_pool[f\"X_test_pq:{p_value}_{q_value}\"] = X_test\n","        model_pool[f\"y_test_pq:{p_value}_{q_value}\"] = y_test"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","best_acc = {'acc': 0.0}\n","\n","for p_value in set_of_pq:\n","    for q_value in set_of_pq:\n","        model = model_pool[f\"model_pq:{p_value}_{q_value}\"]\n","        X_test = model_pool[f\"X_test_pq:{p_value}_{q_value}\"]\n","        y_test = model_pool[f\"y_test_pq:{p_value}_{q_value}\"]\n","\n","        predict_proba = model.predict_proba(X_test)[:,1]\n","        y_pred = model.predict(X_test)\n","        acc = accuracy_score(y_test, y_pred)\n","        auc = roc_auc_score(y_test, predict_proba)\n","        if acc > best_acc['acc']:\n","            best_acc['acc'] = acc\n","            best_acc['auc'] = auc\n","            best_acc['p'] = p_value\n","            best_acc['q'] = q_value\n","\n","        print(f\"--------------Result with p={p_value} and q={q_value}\")\n","        print('Test set AUC: ', auc)\n","        print('Test set Acc: ', acc)\n","\n","print(f'---------Best Acc: p={best_acc[\"p\"]} and q={best_acc[\"q\"]}------------------')\n","print('Test set AUC: ', best_acc['auc'])\n","print('Test set Acc: ', best_acc['acc'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1Rut2KhvIYX","executionInfo":{"status":"ok","timestamp":1684152165447,"user_tz":-420,"elapsed":5367,"user":{"displayName":"Hong Quang Vu","userId":"17616431851570102549"}},"outputId":"041f892e-929d-4418-caa0-a03f299dc051"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------Result with p=0.25 and q=0.25\n","Test set AUC:  0.8935584103255232\n","Test set Acc:  0.8664556962025316\n","--------------Result with p=0.25 and q=0.5\n","Test set AUC:  0.9058290209992683\n","Test set Acc:  0.8681962025316455\n","--------------Result with p=0.25 and q=1\n","Test set AUC:  0.894805742749757\n","Test set Acc:  0.8719936708860759\n","--------------Result with p=0.25 and q=2\n","Test set AUC:  0.8813588629711371\n","Test set Acc:  0.8685126582278481\n","--------------Result with p=0.25 and q=4\n","Test set AUC:  0.8947625\n","Test set Acc:  0.8637658227848102\n","--------------Result with p=0.5 and q=0.25\n","Test set AUC:  0.8994042910191666\n","Test set Acc:  0.8677215189873417\n","--------------Result with p=0.5 and q=0.5\n","Test set AUC:  0.8988507058504432\n","Test set Acc:  0.8775316455696203\n","--------------Result with p=0.5 and q=1\n","Test set AUC:  0.9005782108798329\n","Test set Acc:  0.8737341772151899\n","--------------Result with p=0.5 and q=2\n","Test set AUC:  0.8886148748814041\n","Test set Acc:  0.8669303797468354\n","--------------Result with p=0.5 and q=4\n","Test set AUC:  0.8924745732065633\n","Test set Acc:  0.8670886075949367\n","--------------Result with p=1 and q=0.25\n","Test set AUC:  0.897746339382304\n","Test set Acc:  0.8784810126582279\n","--------------Result with p=1 and q=0.5\n","Test set AUC:  0.8991943964146751\n","Test set Acc:  0.8738924050632911\n","--------------Result with p=1 and q=1\n","Test set AUC:  0.8878512789711464\n","Test set Acc:  0.8672468354430379\n","--------------Result with p=1 and q=2\n","Test set AUC:  0.8976046212121211\n","Test set Acc:  0.8723101265822785\n","--------------Result with p=1 and q=4\n","Test set AUC:  0.8857560038696259\n","Test set Acc:  0.864240506329114\n","--------------Result with p=2 and q=0.25\n","Test set AUC:  0.9081814911907841\n","Test set Acc:  0.8762658227848101\n","--------------Result with p=2 and q=0.5\n","Test set AUC:  0.8905372142390988\n","Test set Acc:  0.8689873417721519\n","--------------Result with p=2 and q=1\n","Test set AUC:  0.903116196808071\n","Test set Acc:  0.8745253164556962\n","--------------Result with p=2 and q=2\n","Test set AUC:  0.9048447125993122\n","Test set Acc:  0.8710443037974683\n","--------------Result with p=2 and q=4\n","Test set AUC:  0.9109419503283862\n","Test set Acc:  0.8780063291139241\n","--------------Result with p=4 and q=0.25\n","Test set AUC:  0.904974351142156\n","Test set Acc:  0.8791139240506329\n","--------------Result with p=4 and q=0.5\n","Test set AUC:  0.8879606316199857\n","Test set Acc:  0.8700949367088607\n","--------------Result with p=4 and q=1\n","Test set AUC:  0.9102427648896851\n","Test set Acc:  0.8786392405063291\n","--------------Result with p=4 and q=2\n","Test set AUC:  0.8886064683977624\n","Test set Acc:  0.8794303797468355\n","--------------Result with p=4 and q=4\n","Test set AUC:  0.8972708775654635\n","Test set Acc:  0.8740506329113924\n","---------Best Acc: p=4 and q=2------------------\n","Test set AUC:  0.8886064683977624\n","Test set Acc:  0.8794303797468355\n"]}]}]}